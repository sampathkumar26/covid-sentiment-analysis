{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc6e87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:57:46.000439Z",
     "iopub.status.busy": "2022-04-12T16:57:45.999693Z",
     "iopub.status.idle": "2022-04-12T16:57:47.230227Z",
     "shell.execute_reply": "2022-04-12T16:57:47.229495Z",
     "shell.execute_reply.started": "2022-04-12T15:21:20.433793Z"
    },
    "papermill": {
     "duration": 1.261985,
     "end_time": "2022-04-12T16:57:47.230385",
     "exception": false,
     "start_time": "2022-04-12T16:57:45.968400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # for text vectorizing\n",
    "from sklearn.model_selection import train_test_split # for splitting the data\n",
    "\n",
    "# for trainig and saving th model\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pickle\n",
    "\n",
    "#  librariesfor cleaning the text\n",
    "import neattext as nt\n",
    "import neattext.functions as nfx\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6279c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:57:47.289730Z",
     "iopub.status.busy": "2022-04-12T16:57:47.288972Z",
     "iopub.status.idle": "2022-04-12T16:57:51.581612Z",
     "shell.execute_reply": "2022-04-12T16:57:51.580795Z",
     "shell.execute_reply.started": "2022-04-12T15:11:55.998150Z"
    },
    "papermill": {
     "duration": 4.324702,
     "end_time": "2022-04-12T16:57:51.581782",
     "exception": false,
     "start_time": "2022-04-12T16:57:47.257080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing the training data\n",
    "traindf = pd.read_csv(\"training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2e040d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:57:51.638037Z",
     "iopub.status.busy": "2022-04-12T16:57:51.637372Z",
     "iopub.status.idle": "2022-04-12T16:57:51.661062Z",
     "shell.execute_reply": "2022-04-12T16:57:51.661589Z",
     "shell.execute_reply.started": "2022-04-12T15:12:00.997694Z"
    },
    "papermill": {
     "duration": 0.053669,
     "end_time": "2022-04-12T16:57:51.661769",
     "exception": false,
     "start_time": "2022-04-12T16:57:51.608100",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NO JOKE I WILL HOP ON A PLANE RN! (Well after ...</td>\n",
       "      <td>0 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BanMediaHouse whose is responsible for spreadi...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Im waiting for someone to say to me that all t...</td>\n",
       "      <td>3 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>He is a liar. Proven day night. Time again. Li...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NEW: U.S. CoronaVirus death toll reaches 4,000...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>Life Insurance? I wonder if policies are payin...</td>\n",
       "      <td>4 5 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>My cousin passed away from the corona virus to...</td>\n",
       "      <td>4 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>I guess Mother Nature really hates us. Yellows...</td>\n",
       "      <td>3 5 9 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>So question for the day that isnt related to c...</td>\n",
       "      <td>9 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dear corona, If you cancel my fucking church c...</td>\n",
       "      <td>6 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              Tweet    Labels\n",
       "0        1  NO JOKE I WILL HOP ON A PLANE RN! (Well after ...      0 10\n",
       "1        2  BanMediaHouse whose is responsible for spreadi...         6\n",
       "2        3  Im waiting for someone to say to me that all t...       3 4\n",
       "3        4  He is a liar. Proven day night. Time again. Li...         6\n",
       "4        5  NEW: U.S. CoronaVirus death toll reaches 4,000...         8\n",
       "...    ...                                                ...       ...\n",
       "4995  4996  Life Insurance? I wonder if policies are payin...     4 5 7\n",
       "4996  4997  My cousin passed away from the corona virus to...       4 5\n",
       "4997  4998  I guess Mother Nature really hates us. Yellows...  3 5 9 10\n",
       "4998  4999  So question for the day that isnt related to c...      9 10\n",
       "4999  5000  Dear corona, If you cancel my fucking church c...      6 10\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531dcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the splitting in the labels column for further use\n",
    "traindf['Labels'] = traindf['Labels'].apply(lambda x: [int(i) for i in x.split()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bf1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the definition of each labels in the dictionary format\n",
    "# this dict we are going to use for creating the extra columns for training over model\n",
    "class_map = {\n",
    "    \"optimistic\": 0,\n",
    "    \"thankful\": 1,\n",
    "    \"empathetic\": 2,\n",
    "    \"pessimistic\": 3,\n",
    "    \"anxious\": 4,\n",
    "    \"sad\": 5,\n",
    "    \"annoyed\": 6,\n",
    "    \"denial\": 7,\n",
    "    \"surprise\": 8,\n",
    "    \"official_report\": 9,\n",
    "    \"joking\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824484da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function we are using for creating/ adding the columns and populating them on the basis of the labels\n",
    "for k,v in class_map.items():\n",
    "    traindf[k]=traindf['Labels'].apply(lambda x: 1 if v  in x else 0)\n",
    "    traindf[k]=traindf[k].astype(float) # converting the numbers into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1aaf172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Labels</th>\n",
       "      <th>optimistic</th>\n",
       "      <th>thankful</th>\n",
       "      <th>empathetic</th>\n",
       "      <th>pessimistic</th>\n",
       "      <th>anxious</th>\n",
       "      <th>sad</th>\n",
       "      <th>annoyed</th>\n",
       "      <th>denial</th>\n",
       "      <th>surprise</th>\n",
       "      <th>official_report</th>\n",
       "      <th>joking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NO JOKE I WILL HOP ON A PLANE RN! (Well after ...</td>\n",
       "      <td>[0, 10]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BanMediaHouse whose is responsible for spreadi...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Im waiting for someone to say to me that all t...</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>He is a liar. Proven day night. Time again. Li...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NEW: U.S. CoronaVirus death toll reaches 4,000...</td>\n",
       "      <td>[8]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>Life Insurance? I wonder if policies are payin...</td>\n",
       "      <td>[4, 5, 7]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>My cousin passed away from the corona virus to...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>I guess Mother Nature really hates us. Yellows...</td>\n",
       "      <td>[3, 5, 9, 10]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>So question for the day that isnt related to c...</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>Dear corona, If you cancel my fucking church c...</td>\n",
       "      <td>[6, 10]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              Tweet         Labels  \\\n",
       "0        1  NO JOKE I WILL HOP ON A PLANE RN! (Well after ...        [0, 10]   \n",
       "1        2  BanMediaHouse whose is responsible for spreadi...            [6]   \n",
       "2        3  Im waiting for someone to say to me that all t...         [3, 4]   \n",
       "3        4  He is a liar. Proven day night. Time again. Li...            [6]   \n",
       "4        5  NEW: U.S. CoronaVirus death toll reaches 4,000...            [8]   \n",
       "...    ...                                                ...            ...   \n",
       "4995  4996  Life Insurance? I wonder if policies are payin...      [4, 5, 7]   \n",
       "4996  4997  My cousin passed away from the corona virus to...         [4, 5]   \n",
       "4997  4998  I guess Mother Nature really hates us. Yellows...  [3, 5, 9, 10]   \n",
       "4998  4999  So question for the day that isnt related to c...        [9, 10]   \n",
       "4999  5000  Dear corona, If you cancel my fucking church c...        [6, 10]   \n",
       "\n",
       "      optimistic  thankful  empathetic  pessimistic  anxious  sad  annoyed  \\\n",
       "0            1.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "1            0.0       0.0         0.0          0.0      0.0  0.0      1.0   \n",
       "2            0.0       0.0         0.0          1.0      1.0  0.0      0.0   \n",
       "3            0.0       0.0         0.0          0.0      0.0  0.0      1.0   \n",
       "4            0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "...          ...       ...         ...          ...      ...  ...      ...   \n",
       "4995         0.0       0.0         0.0          0.0      1.0  1.0      0.0   \n",
       "4996         0.0       0.0         0.0          0.0      1.0  1.0      0.0   \n",
       "4997         0.0       0.0         0.0          1.0      0.0  1.0      0.0   \n",
       "4998         0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "4999         0.0       0.0         0.0          0.0      0.0  0.0      1.0   \n",
       "\n",
       "      denial  surprise  official_report  joking  \n",
       "0        0.0       0.0              0.0     1.0  \n",
       "1        0.0       0.0              0.0     0.0  \n",
       "2        0.0       0.0              0.0     0.0  \n",
       "3        0.0       0.0              0.0     0.0  \n",
       "4        0.0       1.0              0.0     0.0  \n",
       "...      ...       ...              ...     ...  \n",
       "4995     1.0       0.0              0.0     0.0  \n",
       "4996     0.0       0.0              0.0     0.0  \n",
       "4997     0.0       0.0              1.0     1.0  \n",
       "4998     0.0       0.0              1.0     1.0  \n",
       "4999     0.0       0.0              0.0     1.0  \n",
       "\n",
       "[5000 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf # new dataframe looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301d838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c44e139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:57:52.048223Z",
     "iopub.status.busy": "2022-04-12T16:57:52.047467Z",
     "iopub.status.idle": "2022-04-12T16:57:52.059311Z",
     "shell.execute_reply": "2022-04-12T16:57:52.059819Z",
     "shell.execute_reply.started": "2022-04-12T15:12:05.337132Z"
    },
    "papermill": {
     "duration": 0.045677,
     "end_time": "2022-04-12T16:57:52.060006",
     "exception": false,
     "start_time": "2022-04-12T16:57:52.014329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining a function for cleaning the tweets removing some specific words and punctuations\n",
    "def  clean_text(text):\n",
    "    text =  text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"\\r\", \"\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) \n",
    "    text = re.sub(\"(\\\\W)\",\" \",text) \n",
    "    text = re.sub('\\S*\\d\\S*\\s*','', text)\n",
    "    \n",
    "    return text\n",
    "traindf['Tweet'] = traindf['Tweet'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482ce3de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:57:52.123630Z",
     "iopub.status.busy": "2022-04-12T16:57:52.120478Z",
     "iopub.status.idle": "2022-04-12T16:58:24.633515Z",
     "shell.execute_reply": "2022-04-12T16:58:24.632794Z",
     "shell.execute_reply.started": "2022-04-12T15:12:06.053558Z"
    },
    "papermill": {
     "duration": 32.545543,
     "end_time": "2022-04-12T16:58:24.633678",
     "exception": false,
     "start_time": "2022-04-12T16:57:52.088135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now using neattext for removing the stopwards from the tweets which are creating noise in the data\n",
    "\n",
    "traindf['Tweet'].apply(lambda x:nt.TextFrame(x).noise_scan())\n",
    "traindf['Tweet'].apply(lambda x:nt.TextExtractor(x).extract_stopwords())\n",
    "traindf['Tweet'].apply(nfx.remove_stopwords)\n",
    "traindf['Tweet']= traindf['Tweet'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcdf4f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:58:52.675098Z",
     "iopub.status.busy": "2022-04-12T16:58:52.674408Z",
     "iopub.status.idle": "2022-04-12T16:58:52.728381Z",
     "shell.execute_reply": "2022-04-12T16:58:52.727804Z",
     "shell.execute_reply.started": "2022-04-12T15:13:41.358978Z"
    },
    "papermill": {
     "duration": 0.085822,
     "end_time": "2022-04-12T16:58:52.728539",
     "exception": false,
     "start_time": "2022-04-12T16:58:52.642717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "Tweet              0\n",
       "Labels             0\n",
       "optimistic         0\n",
       "thankful           0\n",
       "empathetic         0\n",
       "pessimistic        0\n",
       "anxious            0\n",
       "sad                0\n",
       "annoyed            0\n",
       "denial             0\n",
       "surprise           0\n",
       "official_report    0\n",
       "joking             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.isna().sum() #checking for null values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d16e6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:58:52.796361Z",
     "iopub.status.busy": "2022-04-12T16:58:52.795663Z",
     "iopub.status.idle": "2022-04-12T16:58:52.797745Z",
     "shell.execute_reply": "2022-04-12T16:58:52.797116Z",
     "shell.execute_reply.started": "2022-04-12T15:13:06.223525Z"
    },
    "papermill": {
     "duration": 0.039707,
     "end_time": "2022-04-12T16:58:52.797887",
     "exception": false,
     "start_time": "2022-04-12T16:58:52.758180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividing the data into input and output variables\n",
    "X =  traindf.Tweet\n",
    "y =  traindf.drop(['ID','Labels','Tweet'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95bbc25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:58:52.860739Z",
     "iopub.status.busy": "2022-04-12T16:58:52.859935Z",
     "iopub.status.idle": "2022-04-12T16:58:52.896397Z",
     "shell.execute_reply": "2022-04-12T16:58:52.896896Z",
     "shell.execute_reply.started": "2022-04-12T15:13:06.239659Z"
    },
    "papermill": {
     "duration": 0.069589,
     "end_time": "2022-04-12T16:58:52.897214",
     "exception": false,
     "start_time": "2022-04-12T16:58:52.827625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# splitting the data into train and validation \n",
    "X_train,X_valid, y_train,y_valid= train_test_split(X,y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8461ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:58:52.960547Z",
     "iopub.status.busy": "2022-04-12T16:58:52.959566Z",
     "iopub.status.idle": "2022-04-12T16:58:52.966643Z",
     "shell.execute_reply": "2022-04-12T16:58:52.967241Z",
     "shell.execute_reply.started": "2022-04-12T15:14:22.864721Z"
    },
    "papermill": {
     "duration": 0.040021,
     "end_time": "2022-04-12T16:58:52.967421",
     "exception": false,
     "start_time": "2022-04-12T16:58:52.927400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233    today babys birthday corona virus celebrate co...\n",
       "1056    coronavirus created schools stop april fools d...\n",
       "1686    mr president lie seriousness coronavirus threa...\n",
       "187     wild pandemic big april fools day prank aprilf...\n",
       "3840    thailand confirms new coronavirus cases deaths...\n",
       "                              ...                        \n",
       "2895            let know keeps coronavirus away worth try\n",
       "2763    tory lanes french battle infected corona messy...\n",
       "905     tomorrow day millions contract coronavirus rea...\n",
       "3980                wanna beat corona ass beach w friends\n",
       "235     breaking tablighi jamat donates coronavirus pa...\n",
       "Name: Tweet, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "079ea151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:58:53.033573Z",
     "iopub.status.busy": "2022-04-12T16:58:53.032786Z",
     "iopub.status.idle": "2022-04-12T16:58:53.043606Z",
     "shell.execute_reply": "2022-04-12T16:58:53.044235Z",
     "shell.execute_reply.started": "2022-04-12T15:14:51.021329Z"
    },
    "papermill": {
     "duration": 0.045834,
     "end_time": "2022-04-12T16:58:53.044415",
     "exception": false,
     "start_time": "2022-04-12T16:58:52.998581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimistic</th>\n",
       "      <th>thankful</th>\n",
       "      <th>empathetic</th>\n",
       "      <th>pessimistic</th>\n",
       "      <th>anxious</th>\n",
       "      <th>sad</th>\n",
       "      <th>annoyed</th>\n",
       "      <th>denial</th>\n",
       "      <th>surprise</th>\n",
       "      <th>official_report</th>\n",
       "      <th>joking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      optimistic  thankful  empathetic  pessimistic  anxious  sad  annoyed  \\\n",
       "1233         0.0       0.0         0.0          0.0      0.0  1.0      1.0   \n",
       "1056         0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "1686         0.0       0.0         0.0          0.0      0.0  0.0      1.0   \n",
       "187          1.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "3840         0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "...          ...       ...         ...          ...      ...  ...      ...   \n",
       "2895         1.0       0.0         1.0          0.0      0.0  0.0      0.0   \n",
       "2763         0.0       0.0         0.0          1.0      0.0  0.0      1.0   \n",
       "905          0.0       0.0         0.0          0.0      0.0  0.0      1.0   \n",
       "3980         1.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "235          0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "\n",
       "      denial  surprise  official_report  joking  \n",
       "1233     0.0       0.0              0.0     0.0  \n",
       "1056     0.0       0.0              0.0     1.0  \n",
       "1686     0.0       0.0              0.0     0.0  \n",
       "187      0.0       0.0              1.0     1.0  \n",
       "3840     0.0       1.0              0.0     0.0  \n",
       "...      ...       ...              ...     ...  \n",
       "2895     0.0       0.0              0.0     1.0  \n",
       "2763     0.0       0.0              1.0     0.0  \n",
       "905      0.0       0.0              0.0     1.0  \n",
       "3980     0.0       0.0              0.0     1.0  \n",
       "235      0.0       1.0              0.0     0.0  \n",
       "\n",
       "[4000 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc2e39ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T16:58:53.109181Z",
     "iopub.status.busy": "2022-04-12T16:58:53.108451Z",
     "iopub.status.idle": "2022-04-12T17:00:06.963081Z",
     "shell.execute_reply": "2022-04-12T17:00:06.962452Z",
     "shell.execute_reply.started": "2022-04-12T15:16:09.517338Z"
    },
    "papermill": {
     "duration": 73.888376,
     "end_time": "2022-04-12T17:00:06.963253",
     "exception": false,
     "start_time": "2022-04-12T16:58:53.074877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the word vectorizier for converting the tweets into vectors\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',     \n",
    "    analyzer='word',            \n",
    "    token_pattern=r'\\w{1,}',    \n",
    "    ngram_range=(1, 3),         \n",
    "    stop_words='english',\n",
    "    sublinear_tf=True)\n",
    "\n",
    "word_vectorizer.fit(X_train)    \n",
    "train_word_features = word_vectorizer.transform(X_train)\n",
    "X_train_transformed = word_vectorizer.transform(X_train)\n",
    "X_valid_transformed = word_vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0296fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving vectorizer\n",
    "\n",
    "pickle.dump(word_vectorizer, open(\"vectorizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f193f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Testing phase\n",
    "tf1 = pickle.load(open(\"vectorizer.pkl\", 'rb'))\n",
    "\n",
    "# Create new tfidfVectorizer with old vocabulary\n",
    "\n",
    "word_vectorizer1 = TfidfVectorizer(\n",
    "    strip_accents='unicode',     \n",
    "    analyzer='word',            \n",
    "    token_pattern=r'\\w{1,}',    \n",
    "    ngram_range=(1, 3),         \n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,\n",
    "    vocabulary = tf1.vocabulary_)\n",
    "X_valid_transformed = word_vectorizer1.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f61d5eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T17:00:34.112786Z",
     "iopub.status.busy": "2022-04-12T17:00:34.111911Z",
     "iopub.status.idle": "2022-04-12T17:00:34.126750Z",
     "shell.execute_reply": "2022-04-12T17:00:34.126104Z",
     "shell.execute_reply.started": "2022-04-12T15:19:54.163095Z"
    },
    "papermill": {
     "duration": 0.051628,
     "end_time": "2022-04-12T17:00:34.126891",
     "exception": false,
     "start_time": "2022-04-12T17:00:34.075263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 52149)\t0.29072600101391444\n",
      "  (0, 50525)\t0.6218691546594884\n",
      "  (0, 47791)\t0.36728594052516356\n",
      "  (0, 15422)\t0.34664711953282834\n",
      "  (0, 8876)\t0.3206452801726044\n",
      "  (0, 8701)\t0.0943876144226659\n",
      "  (0, 6327)\t0.34664711953282834\n",
      "  (0, 6106)\t0.20446837480625968\n",
      "  (1, 50786)\t0.3579064045278051\n",
      "  (1, 48878)\t0.2896867468650635\n",
      "  (1, 36457)\t0.29551441584492866\n",
      "  (1, 29381)\t0.48327211945119364\n",
      "  (1, 15371)\t0.48327211945119364\n",
      "  (1, 15370)\t0.48327211945119364\n",
      "  (2, 56651)\t0.3079049134512218\n",
      "  (2, 56631)\t0.27832688835516683\n",
      "  (2, 50810)\t0.2906028779246404\n",
      "  (2, 50786)\t0.228031239697661\n",
      "  (2, 49592)\t0.23922686598940832\n",
      "  (2, 39295)\t0.3079049134512218\n",
      "  (2, 39037)\t0.2906028779246404\n",
      "  (2, 39007)\t0.26102485282858545\n",
      "  (2, 34754)\t0.3079049134512218\n",
      "  (2, 34744)\t0.27832688835516683\n",
      "  (2, 34575)\t0.16806236359399995\n",
      "  :\t:\n",
      "  (998, 26172)\t0.16944220890333828\n",
      "  (998, 24169)\t0.16944220890333828\n",
      "  (998, 24168)\t0.16944220890333828\n",
      "  (998, 24167)\t0.16944220890333828\n",
      "  (998, 10451)\t0.16944220890333828\n",
      "  (998, 8939)\t0.16944220890333828\n",
      "  (998, 8701)\t0.04613696459513924\n",
      "  (998, 3832)\t0.16944220890333828\n",
      "  (998, 3831)\t0.16944220890333828\n",
      "  (998, 3830)\t0.16944220890333828\n",
      "  (998, 1431)\t0.16944220890333828\n",
      "  (998, 1430)\t0.16944220890333828\n",
      "  (998, 1429)\t0.16944220890333828\n",
      "  (998, 1428)\t0.16944220890333828\n",
      "  (998, 1423)\t0.2868905982725365\n",
      "  (999, 43813)\t0.37752417957679396\n",
      "  (999, 43758)\t0.20508435495663638\n",
      "  (999, 16551)\t0.26256429649668894\n",
      "  (999, 13807)\t0.3412583742256268\n",
      "  (999, 9745)\t0.37752417957679396\n",
      "  (999, 9735)\t0.2570517818970355\n",
      "  (999, 8701)\t0.09701870604188394\n",
      "  (999, 7782)\t0.37752417957679396\n",
      "  (999, 7781)\t0.3563100433879086\n",
      "  (999, 5859)\t0.37752417957679396\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c161006a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimistic</th>\n",
       "      <th>thankful</th>\n",
       "      <th>empathetic</th>\n",
       "      <th>pessimistic</th>\n",
       "      <th>anxious</th>\n",
       "      <th>sad</th>\n",
       "      <th>annoyed</th>\n",
       "      <th>denial</th>\n",
       "      <th>surprise</th>\n",
       "      <th>official_report</th>\n",
       "      <th>joking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      optimistic  thankful  empathetic  pessimistic  anxious  sad  annoyed  \\\n",
       "1233         0.0       0.0         0.0          0.0      0.0  1.0      1.0   \n",
       "1056         0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "1686         0.0       0.0         0.0          0.0      0.0  0.0      1.0   \n",
       "187          1.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "3840         0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "...          ...       ...         ...          ...      ...  ...      ...   \n",
       "2895         1.0       0.0         1.0          0.0      0.0  0.0      0.0   \n",
       "2763         0.0       0.0         0.0          1.0      0.0  0.0      1.0   \n",
       "905          0.0       0.0         0.0          0.0      0.0  0.0      1.0   \n",
       "3980         1.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "235          0.0       0.0         0.0          0.0      0.0  0.0      0.0   \n",
       "\n",
       "      denial  surprise  official_report  joking  \n",
       "1233     0.0       0.0              0.0     0.0  \n",
       "1056     0.0       0.0              0.0     1.0  \n",
       "1686     0.0       0.0              0.0     0.0  \n",
       "187      0.0       0.0              1.0     1.0  \n",
       "3840     0.0       1.0              0.0     0.0  \n",
       "...      ...       ...              ...     ...  \n",
       "2895     0.0       0.0              0.0     1.0  \n",
       "2763     0.0       0.0              1.0     0.0  \n",
       "905      0.0       0.0              0.0     1.0  \n",
       "3980     0.0       0.0              0.0     1.0  \n",
       "235      0.0       1.0              0.0     0.0  \n",
       "\n",
       "[4000 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf4e467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T17:00:34.192075Z",
     "iopub.status.busy": "2022-04-12T17:00:34.191376Z",
     "iopub.status.idle": "2022-04-12T17:02:42.566719Z",
     "shell.execute_reply": "2022-04-12T17:02:42.567371Z",
     "shell.execute_reply.started": "2022-04-12T16:54:45.121995Z"
    },
    "papermill": {
     "duration": 128.409826,
     "end_time": "2022-04-12T17:02:42.567582",
     "exception": false,
     "start_time": "2022-04-12T17:00:34.157756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score Train: 0.9999559543477646\n",
      "ROC AUC Score Test: 0.7249252332202116\n",
      "ROC AUC Score Train: 0.9999559543477646\n",
      "ROC AUC Score Test: 0.7249252332202116\n"
     ]
    }
   ],
   "source": [
    "# defining the classifier here we are using SGDclassifier \n",
    "# Stochastic Gradient Descent (SGD) is a simple yet efficient optimization algorithm used to find the values of parameters/coefficients of  functions that minimize a cost function.\n",
    "# OneVsRestClassifier is the heuristic method for using binary classification algorithms for multi-class classification\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(random_state=0,loss='log',alpha=0.00001,penalty='elasticnet'))\n",
    "classifier.fit(X_train_transformed, y_train.values)\n",
    "\n",
    "\n",
    "y_train_pred_proba = classifier.predict_proba(X_train_transformed)\n",
    "y_valid_pred_proba = classifier.predict_proba(X_valid_transformed)\n",
    "\n",
    "\n",
    "roc_auc_score_train = roc_auc_score(y_train, y_train_pred_proba,average='weighted')\n",
    "roc_auc_score_test = roc_auc_score(y_valid, y_valid_pred_proba,average='weighted')\n",
    "\n",
    "print(\"ROC AUC Score Train:\", roc_auc_score_train)\n",
    "print(\"ROC AUC Score Test:\", roc_auc_score_test)\n",
    "\n",
    "y_train_pred_proba = classifier.predict_proba(X_train_transformed)\n",
    "y_valid_pred_proba = classifier.predict_proba(X_valid_transformed)\n",
    "\n",
    "\n",
    "roc_auc_score_train = roc_auc_score(y_train, y_train_pred_proba,average='weighted')\n",
    "roc_auc_score_test = roc_auc_score(y_valid, y_valid_pred_proba,average='weighted')\n",
    "\n",
    "print(\"ROC AUC Score Train:\", roc_auc_score_train)\n",
    "print(\"ROC AUC Score Test:\", roc_auc_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a1f5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(classifier, open(\"model.sav\", 'wb'))\n",
    "\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(\"model.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8435ece",
   "metadata": {},
   "source": [
    "# Testing for converting it into flask model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "716af525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08643883, 0.06702587, 0.00199414, 0.16072289, 0.01187621,\n",
       "       0.00663967, 0.62903415, 0.44444518, 0.02572794, 0.62336515,\n",
       "       0.09330877])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_pred_proba[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b8784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annoyed', 'official_report']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in dict(zip(class_map.keys(),  y_valid_pred_proba[1] )).items() if v >=0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "403f5f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08643883, 0.06702587, 0.00199414, 0.16072289, 0.01187621,\n",
       "        0.00663967, 0.62903415, 0.44444518, 0.02572794, 0.62336515,\n",
       "        0.09330877]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_proba(X_valid_transformed[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a37166ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['optimistic', 'thankful', 'empathetic', 'pessimistic', 'anxious', 'sad', 'annoyed', 'denial', 'surprise', 'official_report', 'joking'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9437fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08643883, 0.06702587, 0.00199414, 0.16072289, 0.01187621,\n",
       "       0.00663967, 0.62903415, 0.44444518, 0.02572794, 0.62336515,\n",
       "       0.09330877])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_pred_proba[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1b7bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=\"Fact:- The words Corona and Dalgona rhymes perfectly. Maybe this is the reason behind the trend dalgonaCoffee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d2f5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['official_report', 'joking']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# importing the vectorizer\n",
    "tf1 = pickle.load(open(\"vectorizer.pkl\", 'rb'))\n",
    "# importing the model\n",
    "loaded_model = pickle.load(open(\"model.sav\", 'rb'))\n",
    "\n",
    "# defining a function for cleaning the tweets removing some specific words and punctuations\n",
    "def  clean_text(text):\n",
    "    text =  text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"\\r\", \"\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) \n",
    "    text = re.sub(\"(\\\\W)\",\" \",text) \n",
    "    text = re.sub('\\S*\\d\\S*\\s*','', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# defining the definition of each labels in the dictionary format\n",
    "# this dict we are going to use for creating the extra columns for training over model\n",
    "class_map = {\n",
    "    \"optimistic\": 0,\n",
    "    \"thankful\": 1,\n",
    "    \"empathetic\": 2,\n",
    "    \"pessimistic\": 3,\n",
    "    \"anxious\": 4,\n",
    "    \"sad\": 5,\n",
    "    \"annoyed\": 6,\n",
    "    \"denial\": 7,\n",
    "    \"surprise\": 8,\n",
    "    \"official_report\": 9,\n",
    "    \"joking\": 10}\n",
    "\n",
    "word_vectorizer1 = TfidfVectorizer(\n",
    "            strip_accents='unicode',     \n",
    "            analyzer='word',            \n",
    "            token_pattern=r'\\w{1,}',    \n",
    "            ngram_range=(1, 3),         \n",
    "            stop_words='english',\n",
    "            sublinear_tf=True,\n",
    "            vocabulary = tf1.vocabulary_)\n",
    "\n",
    "\n",
    "def submit(texts):\n",
    "    texts = clean_text(texts)\n",
    "    text_trans = word_vectorizer1.fit_transform([texts])\n",
    "    y_pred = loaded_model.predict_proba(text_trans)\n",
    "    predictions = [k for k,v in dict(zip(class_map.keys(),  y_pred[0] )).items() if v >=0.5]\n",
    "    try:\n",
    "        predictions = [k for k,v in dict(zip(class_map.keys(),  y_pred[0] )).items() if v >=0.5]\n",
    "    except:\n",
    "        predictions = \"No labels are associated with it\"\n",
    "\n",
    "    return predictions\n",
    "\n",
    "print(submit(texts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 308.503293,
   "end_time": "2022-04-12T17:02:44.222795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-12T16:57:35.719502",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
